var chunkingStreams = require("chunking-streams"),
  fs = require("fs"),
  xxhash = require("xxhash"),
  util = require("util"),
  events = require("events"),
  StreamBouncer = require("stream-bouncer"),
  FsDiffStream = function(e) {
    function n(e, n, t) {
      c.emit(e, n, t)
    }

    function t(e, n) {
      c.on(e, n)
    }
    if (!(this instanceof FsDiffStream)) return new FsDiffStream(e);
    e = e || {}, e.chunkSize || e.chunkCount || (e.chunkSize = 2048), e.debug = e.debug || !1;
    var i, u, a, r, s, o = chunkingStreams.SizeChunker,
      h = {},
      c = this,
      l = new StreamBouncer({
        streamsPerTick: 1,
        poll: 100
      });
    l.on("count", function(n) {
      e.debug && console.log(n + " streams remaining")
    }), l.on("start", function(n) {
      e.debug && console.log(n.path + " started")
    }), l.on("close", function(n) {
      e.debug && console.log(n.path + " finished"), i && process.nextTick(function() {
        i(null, u)
      })
    });
    var f = function(e) {
        h[s] || (h[s] = {
          totalChunks: a
        });
        var t = h[s];
        t[e.id] ? t[e.id].length >= 1 && (2 == t[e.id].length && t[e.id].splice(0, 1), t[e.id].push(e), d(t[e.id])) : (t[e.id] = [e], n("uniqueChunk", null, {
          fileName: s,
          data: new Buffer(JSON.parse(JSON.stringify(e.data))),
          targetChunkSize: r,
          length: e.data.length,
          id: e.id
        }), delete e.data)
      },
      d = function(e) {
        var t = e[0].hash == e[1].hash;
        t || (e[1].data ? (n("chunkChanged", null, {
          fileName: s,
          data: new Buffer(JSON.parse(JSON.stringify(e[1].data))),
          targetChunkSize: r,
          length: e[1].data.length,
          id: e[1].id
        }), delete e[1].data) : n("chunkRemoved", null, e[1].id))
      },
      k = function() {
        if (u = null, !e.chunkCount) {
          r = e.chunkSize, a = h[s] && h[s].totalChunks ? h[s].totalChunks : void 0;
          var t = Math.floor(fs.statSync(s).size / e.chunkSize) + 1;
          if (a && a != t) {
            a = t;
            var i = h[s].totalChunks;
            h[s].totalChunks = a, n("fileResize", null, {
              fileName: s,
              chunkCount: a,
              prevChunkCount: i
            }), u = {
              fileName: s,
              chunkCount: a,
              prevChunkCount: i
            }
          } else a = t;
          return r
        }
        return a = e.chunkCount, r = Math.floor(fs.statSync(s).size / e.chunkCount) + 1
      },
      m = function(e) {
        var n = fs.createReadStream(e),
          t = new o({
            chunkSize: k(),
            flushTail: !0
          });
        t.on("data", function(e) {
          0 != e.data.length && (e.hash = xxhash.hash(e.data, 3405691582), f(e))
        }), l.push({
          source: n,
          destination: t
        })
      },
      S = function(e) {
        delete h[e]
      },
      g = function(e, n) {
        i = n, s = e, process.nextTick(function() {
          return fs.existsSync(s) ? void m(s) : void i(s + " doesn't exist :(")
        })
      };
    return {
      compare: g,
      remove: S,
      on: t
    }
  };
util.inherits(FsDiffStream, events.EventEmitter), module.exports = FsDiffStream;
